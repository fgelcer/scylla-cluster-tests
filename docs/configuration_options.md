# scylla-cluster-tests configuration options
| Parameter | Description  | Default | Override environment<br>variable
| :-------  | :----------  | :------ | :-------------------------------
| **<a name="config_files">config_files</a>**  | a list of config files that would be used | N/A | SCT_CONFIG_FILES
| **<a name="cluster_backend">cluster_backend</a>**  | backend that will be used, aws/gce/docker/libvirt/openstack | docker | SCT_CLUSTER_BACKEND
| **<a name="test_duration">test_duration</a>**  | Test duration (min). Parameter used to keep instances produced by tests that are<br>supposed to run longer than 24 hours from being killed | 600 | SCT_TEST_DURATION
| **<a name="n_db_nodes">n_db_nodes</a>**  | Number list of database nodes in multiple data centers. | 3 | SCT_N_DB_NODES
| **<a name="n_loaders">n_loaders</a>**  | Number list of loader nodes in multiple data centers | 1 | SCT_N_LOADERS
| **<a name="n_monitor_nodes">n_monitor_nodes</a>**  | Number list of monitor nodes in multiple data centers | 1 | SCT_N_MONITORS_NODES
| **<a name="post_behavior_db_nodes">post_behavior_db_nodes</a>**  | Failure/post test behavior for scylladb node instances. i.e. what to do with the cloud instances at the end of the test.<br><br>'destroy' - Destroy instances and credentials (default)<br>'keep' - Keep instances running and leave credentials alone<br>'keep-on-failure' - Keep instances running if sct test run detect critical errors and leave credentials alone | destroy | SCT_POST_BEHAVIOR_DB_NODES
| **<a name="post_behavior_loader_nodes">post_behavior_loader_nodes</a>**  | Failure/post test behavior for loader node instances. i.e. what to do with the cloud instances at the end of the test.<br><br>'destroy' - Destroy instances and credentials (default)<br>'keep' - Keep instances running and leave credentials alone<br>'keep-on-failure' - Keep instances running if sct test run detect critical errors and leave credentials alone | destroy | SCT_POST_BEHAVIOR_LOADER_NODES
| **<a name="post_behavior_monitor_nodes">post_behavior_monitor_nodes</a>**  | Failure/post test behavior for scylladb monitor instances. i.e. what to do with the cloud instances at the end of the test.<br><br>'destroy' - Destroy instances and credentials (default)<br>'keep' - Keep instances running and leave credentials alone<br>'keep-on-failure' - Keep instances running if sct test run detect critical errors and leave credentials alone | destroy | SCT_POST_BEHAVIOR_MONITOR_NODES
| **<a name="endpoint_snitch">endpoint_snitch</a>**  | The snitch class scylla would use<br><br>'GossipingPropertyFileSnitch' - default<br>'Ec2MultiRegionSnitch' - default on aws backend<br>'GoogleCloudSnitch' | N/A | SCT_ENDPOINT_SNITCH
| **<a name="user_credentials_path">user_credentials_path</a>**  | Path to your user credentials. qa key are downloaded automatically from S3 bucket | ~/.ssh/scylla-test | SCT_USER_CREDENTIALS_PATH
| **<a name="ip_ssh_connections">ip_ssh_connections</a>**  | Type of IP used to connect to machine instances.<br>This depends on whether you are running your tests from a machine inside<br>your cloud provider, where it makes sense to use 'private', or outside (use 'public')<br><br>Default: Use public IPs to connect to instances (public)<br>Use private IPs to connect to instances (private) | public | SCT_IP_SSH_CONNECTIONS
| **<a name="scylla_repo">scylla_repo</a>**  | Url to the repo of scylla version to install scylla | N/A | SCT_SCYLLA_REPO
| **<a name="scylla_version">scylla_version</a>**  | Version of scylla to install, ex. '2.3.1'<br>Automatically lookup AMIs and repo links for formal versions.<br>WARNING: can't be used together with 'scylla_repo' or 'ami_id_db_scylla' | N/A | SCT_SCYLLA_VERSION
| **<a name="scylla_repo_m">scylla_repo_m</a>**  | Url to the repo of scylla version to install scylla from for managment tests | N/A | SCT_SCYLLA_REPO_M
| **<a name="scylla_mgmt_repo">scylla_mgmt_repo</a>**  | Url to the repo of scylla manager version to install for management tests | N/A | SCT_SCYLLA_MGMT_REPO
| **<a name="use_mgmt">use_mgmt</a>**  | When define true, will install scylla management | N/A | SCT_USE_MGMT
| **<a name="mgmt_port">mgmt_port</a>**  | The port of scylla management | N/A | SCT_MGMT_PORT
| **<a name="update_db_packages">update_db_packages</a>**  | A local directory of rpms to install a custom version on top of<br>the scylla installed (or from repo or from ami) | N/A | SCT_UPDATE_DB_PACKAGES
| **<a name="monitor_branch">monitor_branch</a>**  | The port of scylla management | branch-2.1 | SCT_MONITOR_BRANCH
| **<a name="db_type">db_type</a>**  | Db type to install into db nodes, scylla/cassandra | scylla | SCT_DB_TYPE
| **<a name="user_prefix">user_prefix</a>**  | the prefix of the name of the cloud instances, defaults to username | False | SCT_USER_PREFIX
| **<a name="ami_id_db_scylla_desc">ami_id_db_scylla_desc</a>**  | version name to report stats to Elasticsearch | N/A | SCT_AMI_ID_DB_SCYLLA_DESC
| **<a name="store_results_in_elasticsearch">store_results_in_elasticsearch</a>**  | save the results in elasticsearch | True | SCT_STORE_RESULTS_IN_ELASTICSEARCH
| **<a name="sct_public_ip">sct_public_ip</a>**  | Override the default hostname address of the sct test runner,<br>for the monitoring of the Nemesis.<br>can only work out of the box in AWS | N/A | SCT_SCT_PUBLIC_IP
| **<a name="reuse_cluster">reuse_cluster</a>**  | If true `test_id` would be used to run a test with existing cluster.<br>You have to define all the nodes ip addresses both public and private:<br><br>`reuse_cluster: True`<br>`test_id: 7dc6db84-eb01-4b61-a946-b5c72e0f6d71`<br>`db_nodes_public_ip: []`<br>`db_nodes_private_ip: []`<br>`loaders_public_ip: []`<br>`loaders_private_ip: []`<br>`monitor_nodes_public_ip: []`<br>`monitor_nodes_private_ip: []` | False | SCT_REUSE_CLUSTER
| **<a name="test_id">test_id</a>**  | see [`reuse_cluster`](#reuse_cluster) for more info on usage. | N/A | SCT_TEST_ID
| **<a name="seeds_selector">seeds_selector</a>**  | How to select the seeds. Expected values: reflector/random/first | first | SCT_SEEDS_SELECTOR
| **<a name="seeds_num">seeds_num</a>**  | Number of seeds to select | 1 | SCT_SEEDS_NUM
| **<a name="send_email">send_email</a>**  | If true would send email out of the performance regression test | N/A | SCT_SEND_EMAIL
| **<a name="email_recipients">email_recipients</a>**  | list of email of send the performance regression test to | N/A | SCT_EMAIL_RECIPIENTS
| **<a name="bench_run">bench_run</a>**  | If true would kill the scylla-bench thread in the test teardown | N/A | SCT_BENCH_RUN
| **<a name="fullscan">fullscan</a>**  | If true would kill the fullscan thread in the test teardown | N/A | SCT_FULLSCAN
| **<a name="experimental">experimental</a>**  | when enabled scylla will use it's experimental features | N/A | SCT_EXPERIMENTAL
| **<a name="enable_tc">enable_tc</a>**  | when enable scylla will use traffic control | N/A | SCT_ENABLE_TC
| **<a name="server_encrypt">server_encrypt</a>**  | when enable scylla will use encryption on the server side | N/A | SCT_SERVER_ENCRYPT
| **<a name="client_encrypt">client_encrypt</a>**  | when enable scylla will use encryption on the client side | N/A | SCT_CLIENT_ENCRYPT
| **<a name="hinted_handoff">hinted_handoff</a>**  | when enable or disable scylla hinted handoff | N/A | SCT_HINTED_HANDOFF
| **<a name="authenticator">authenticator</a>**  | which authenticator scylla will use AllowAllAuthenticator/PasswordAuthenticator | N/A | SCT_AUTHENTICATOR
| **<a name="append_scylla_args">append_scylla_args</a>**  | More arguments to append to scylla command line | N/A | SCT_APPEND_SCYLLA_ARGS
| **<a name="append_scylla_yaml">append_scylla_yaml</a>**  | More configuration to append to /etc/scylla/scylla.yaml | N/A | SCT_APPEND_SCYLLA_YAML
| **<a name="nemesis_class_name">nemesis_class_name</a>**  | Nemesis class to use (possible types in sdcm.nemesis). | NoOpMonkey | SCT_NEMESIS_CLASS_NAME
| **<a name="nemesis_interval">nemesis_interval</a>**  | Nemesis sleep interval to use if None provided specifically in the test | N/A | SCT_NEMESIS_INTERVAL
| **<a name="nemesis_during_prepare">nemesis_during_prepare</a>**  | Run nemesis during prepare stage of the test | False | SCT_NEMESIS_DURING_PREPARE
| **<a name="nemesis_run">nemesis_run</a>**  | Run nemesis or not. Used in scale test | True | SCT_NEMESIS_RUN
| **<a name="space_node_threshold">space_node_threshold</a>**  | Space node threshold before starting nemesis (bytes)<br>The default value is 6GB (6x1024^3 bytes)<br>This value is supposed to reproduce<br>https://github.com/scylladb/scylla/issues/1140 | 6442450944 | SCT_SPACE_NODE_THRESHOLD
| **<a name="stress_cmd">stress_cmd</a>**  | cassandra-stress commands.<br>You can specify everything but the -node parameter, which is going to<br>be provided by the test suite infrastructure.<br>multiple commands can passed as a list | N/A | SCT_STRESS_CMD
| **<a name="gemini_url">gemini_url</a>**  | Url of download of the binaries of gemini tool | N/A | SCT_GEMINI_URL
| **<a name="gemini_static_url">gemini_static_url</a>**  | Url of the schema/configuration the gemini tool would use | N/A | SCT_GEMINI_STATIC_URL
| **<a name="gemini_cmd">gemini_cmd</a>**  | gemini command to run (for now used only in GeminiTest) | N/A | SCT_GEMINI_CMD
| **<a name="instance_type_loader">instance_type_loader</a>**  | AWS image type of the loader node | N/A | SCT_INSTANCE_TYPE_LOADER
| **<a name="instance_type_monitor">instance_type_monitor</a>**  | AWS image type of the monitor node | N/A | SCT_INSTANCE_TYPE_MONITOR
| **<a name="instance_type_db">instance_type_db</a>**  | AWS image type of the db node | N/A | SCT_INSTANCE_TYPE_DB
| **<a name="region_name">region_name</a>**  | AWS regions to use | N/A | SCT_REGION_NAME
| **<a name="security_group_ids">security_group_ids</a>**  | AWS security groups ids to use | N/A | SCT_SECURITY_GROUP_IDS
| **<a name="subnet_id">subnet_id</a>**  | AWS subnet ids to use | N/A | SCT_SUBNET_ID
| **<a name="ami_id_db_scylla">ami_id_db_scylla</a>**  | AMS AMI id to use for scylla db node | N/A | SCT_AMI_ID_DB_SCYLLA
| **<a name="ami_id_loader">ami_id_loader</a>**  | AMS AMI id to use for loader node | N/A | SCT_AMI_ID_LOADER
| **<a name="ami_id_monitor">ami_id_monitor</a>**  | AMS AMI id to use for monitor node | N/A | SCT_AMI_ID_MONITOR
| **<a name="ami_id_db_cassandra">ami_id_db_cassandra</a>**  | AMS AMI id to use for cassandra node | N/A | SCT_AMI_ID_DB_CASSANDRA
| **<a name="aws_root_disk_size_monitor">aws_root_disk_size_monitor</a>**  |  | N/A | SCT_AWS_ROOT_DISK_SIZE_MONITOR
| **<a name="aws_root_disk_name_monitor">aws_root_disk_name_monitor</a>**  |  | N/A | SCT_AWS_ROOT_DISK_NAME_MONITOR
| **<a name="ami_db_scylla_user">ami_db_scylla_user</a>**  |  | N/A | SCT_AMI_DB_SCYLLA_USER
| **<a name="ami_monitor_user">ami_monitor_user</a>**  |  | N/A | SCT_AMI_MONITOR_USER
| **<a name="ami_loader_user">ami_loader_user</a>**  |  | N/A | SCT_AMI_LOADER_USER
| **<a name="ami_db_cassandra_user">ami_db_cassandra_user</a>**  |  | N/A | SCT_AMI_DB_CASSANDRA_USER
| **<a name="instance_provision">instance_provision</a>**  | aws instance_provision: on_demand|spot_fleet|spot_low_price|spot_duration | spot_low_price | SCT_AMI_DB_CASSANDRA_USER
| **<a name="gce_datacenter">gce_datacenter</a>**  |  | N/A | SCT_GCE_DATACENTER
| **<a name="gce_network">gce_network</a>**  |  | N/A | SCT_GCE_DATACENTER
| **<a name="gce_image">gce_image</a>**  |  | N/A | SCT_GCE_IMAGE
| **<a name="gce_image_username">gce_image_username</a>**  |  | N/A | SCT_GCE_IMAGE_USERNAME
| **<a name="gce_instance_type_loader">gce_instance_type_loader</a>**  |  | N/A | SCT_GCE_INSTANCE_TYPE_LOADER
| **<a name="gce_root_disk_type_loader">gce_root_disk_type_loader</a>**  |  | N/A | SCT_GCE_ROOT_DISK_TYPE_LOADER
| **<a name="gce_n_local_ssd_disk_loader">gce_n_local_ssd_disk_loader</a>**  |  | N/A | SCT_GCE_N_LOCAL_SSD_DISK_LOADER
| **<a name="gce_instance_type_monitor">gce_instance_type_monitor</a>**  |  | N/A | SCT_GCE_INSTANCE_TYPE_MONITOR
| **<a name="gce_root_disk_type_monitor">gce_root_disk_type_monitor</a>**  |  | N/A | SCT_GCE_ROOT_DISK_TYPE_MONITOR
| **<a name="gce_root_disk_size_monitor">gce_root_disk_size_monitor</a>**  |  | N/A | SCT_GCE_ROOT_DISK_SIZE_MONITOR
| **<a name="gce_n_local_ssd_disk_monitor">gce_n_local_ssd_disk_monitor</a>**  |  | N/A | SCT_GCE_N_LOCAL_SSD_DISK_MONITOR
| **<a name="gce_instance_type_db">gce_instance_type_db</a>**  |  | N/A | SCT_GCE_INSTANCE_TYPE_DB
| **<a name="gce_root_disk_type_db">gce_root_disk_type_db</a>**  |  | N/A | SCT_GCE_ROOT_DISK_TYPE_DB
| **<a name="gce_root_disk_size_db">gce_root_disk_size_db</a>**  |  | N/A | SCT_GCE_ROOT_DISK_SIZE_DB
| **<a name="gce_n_local_ssd_disk_db">gce_n_local_ssd_disk_db</a>**  |  | N/A | SCT_GCE_N_LOCAL_SSD_DISK_DB
| **<a name="docker_image">docker_image</a>**  |  | N/A | SCT_DOCKER_IMAGE
| **<a name="libvirt_uri">libvirt_uri</a>**  |  | N/A | SCT_LIBVIRT_URI
| **<a name="libvirt_bridge">libvirt_bridge</a>**  |  | N/A | SCT_LIBVIRT_BRIDGE
| **<a name="libvirt_loader_image">libvirt_loader_image</a>**  |  | N/A | SCT_LIBVIRT_LOADER_IMAGE
| **<a name="libvirt_loader_image_user">libvirt_loader_image_user</a>**  |  | N/A | SCT_LIBVIRT_LOADER_IMAGE_USER
| **<a name="libvirt_loader_image_password">libvirt_loader_image_password</a>**  |  | N/A | SCT_LIBVIRT_LOADER_IMAGE_PASSWORD
| **<a name="libvirt_loader_os_type">libvirt_loader_os_type</a>**  |  | N/A | SCT_LIBVIRT_LOADER_OS_TYPE
| **<a name="libvirt_loader_os_variant">libvirt_loader_os_variant</a>**  |  | N/A | SCT_LIBVIRT_LOADER_OS_VARIANT
| **<a name="libvirt_loader_memory">libvirt_loader_memory</a>**  |  | N/A | SCT_LIBVIRT_LOADER_MEMORY
| **<a name="libvirt_db_image">libvirt_db_image</a>**  |  | N/A | SCT_LIBVIRT_DB_IMAGE
| **<a name="libvirt_db_image_user">libvirt_db_image_user</a>**  |  | N/A | SCT_LIBVIRT_DB_IMAGE_USER
| **<a name="libvirt_db_image_password">libvirt_db_image_password</a>**  |  | N/A | SCT_LIBVIRT_DB_IMAGE_PASSWORD
| **<a name="libvirt_db_os_type">libvirt_db_os_type</a>**  |  | N/A | SCT_LIBVIRT_DB_OS_TYPE
| **<a name="libvirt_db_os_variant">libvirt_db_os_variant</a>**  |  | N/A | SCT_LIBVIRT_DB_OS_VARIANT
| **<a name="libvirt_db_memory">libvirt_db_memory</a>**  |  | N/A | SCT_LIBVIRT_DB_MEMORY
| **<a name="libvirt_monitor_image">libvirt_monitor_image</a>**  |  | N/A | SCT_LIBVIRT_MONITOR_IMAGE
| **<a name="libvirt_monitor_image_user">libvirt_monitor_image_user</a>**  |  | N/A | SCT_LIBVIRT_MONITOR_IMAGE_USER
| **<a name="libvirt_monitor_image_password">libvirt_monitor_image_password</a>**  |  | N/A | SCT_LIBVIRT_MONITOR_IMAGE_PASSWORD
| **<a name="libvirt_monitor_os_type">libvirt_monitor_os_type</a>**  |  | N/A | SCT_LIBVIRT_MONITOR_OS_TYPE
| **<a name="libvirt_monitor_os_variant">libvirt_monitor_os_variant</a>**  |  | N/A | SCT_LIBVIRT_MONITOR_OS_VARIANT
| **<a name="libvirt_monitor_memory">libvirt_monitor_memory</a>**  |  | N/A | SCT_LIBVIRT_MONITOR_MEMORY
| **<a name="db_nodes_private_ip">db_nodes_private_ip</a>**  |  | N/A | SCT_DB_NODES_PRIVATE_IP
| **<a name="db_nodes_public_ip">db_nodes_public_ip</a>**  |  | N/A | SCT_DB_NODES_PUBLIC_IP
| **<a name="loader_nodes_private_ip">loader_nodes_private_ip</a>**  |  | N/A | SCT_LOADER_NODES_PRIVATE_IP
| **<a name="loader_nodes_public_ip">loader_nodes_public_ip</a>**  |  | N/A | SCT_LOADER_NODES_PUBLIC_IP
| **<a name="monitor_nodes_private_ip">monitor_nodes_private_ip</a>**  |  | N/A | SCT_MONITOR_NODES_PRIVATE_IP
| **<a name="monitor_nodes_public_ip">monitor_nodes_public_ip</a>**  |  | N/A | SCT_MONITOR_NODES_PUBLIC_IP
| **<a name="openstack_user">openstack_user</a>**  |  | N/A | SCT_OPENSTACK_USER
| **<a name="openstack_password">openstack_password</a>**  |  | N/A | SCT_OPENSTACK_PASSWORD
| **<a name="openstack_tenant">openstack_tenant</a>**  |  | N/A | SCT_OPENSTACK_TENANT
| **<a name="openstack_auth_version">openstack_auth_version</a>**  |  | N/A | SCT_OPENSTACK_AUTH_VERSION
| **<a name="openstack_auth_url">openstack_auth_url</a>**  |  | N/A | SCT_OPENSTACK_AUTH_URL
| **<a name="openstack_service_type">openstack_service_type</a>**  |  | N/A | SCT_OPENSTACK_SERVICE_TYPE
| **<a name="openstack_service_name">openstack_service_name</a>**  |  | N/A | SCT_OPENSTACK_SERVICE_NAME
| **<a name="openstack_service_region">openstack_service_region</a>**  |  | N/A | SCT_OPENSTACK_SERVICE_REGION
| **<a name="openstack_instance_type_loader">openstack_instance_type_loader</a>**  |  | N/A | SCT_OPENSTACK_INSTANCE_TYPE_LOADER
| **<a name="openstack_instance_type_db">openstack_instance_type_db</a>**  |  | N/A | SCT_OPENSTACK_INSTANCE_TYPE_DB
| **<a name="openstack_instance_type_monitor">openstack_instance_type_monitor</a>**  |  | N/A | SCT_OPENSTACK_INSTANCE_TYPE_MONITOR
| **<a name="openstack_image">openstack_image</a>**  |  | N/A | SCT_OPENSTACK_IMAGE
| **<a name="openstack_image_username">openstack_image_username</a>**  |  | N/A | SCT_OPENSTACK_IMAGE_USERNAME
| **<a name="openstack_network">openstack_network</a>**  |  | N/A | SCT_OPENSTACK_NETWORK
| **<a name="cassandra_stress_population_size">cassandra_stress_population_size</a>**  |  | N/A | SCT_CASSANDRA_STRESS_POPULATION_SIZE
| **<a name="cassandra_stress_threads">cassandra_stress_threads</a>**  |  | N/A | SCT_CASSANDRA_STRESS_THREADS
| **<a name="add_node_cnt">add_node_cnt</a>**  |  | N/A | SCT_ADD_NODE_CNT
| **<a name="stress_multiplier">stress_multiplier</a>**  |  | N/A | SCT_STRESS_MULTIPLIER
| **<a name="run_fullscan">run_fullscan</a>**  |  | N/A | SCT_RUN_FULLSCAN
| **<a name="keyspace_num">keyspace_num</a>**  |  | N/A | SCT_KEYSPACE_NUM
| **<a name="round_robin">round_robin</a>**  |  | N/A | SCT_ROUND_ROBIN
| **<a name="batch_size">batch_size</a>**  |  | N/A | SCT_BATCH_SIZE
| **<a name="pre_create_schema">pre_create_schema</a>**  |  | N/A | SCT_PRE_CREATE_SCHEMA
| **<a name="stress_read_cmd">stress_read_cmd</a>**  | cassandra-stress commands.<br>You can specify everything but the -node parameter, which is going to<br>be provided by the test suite infrastructure.<br>multiple commands can passed as a list | N/A | SCT_STRESS_READ_CMD
| **<a name="prepare_verify_cmd">prepare_verify_cmd</a>**  | cassandra-stress commands.<br>You can specify everything but the -node parameter, which is going to<br>be provided by the test suite infrastructure.<br>multiple commands can passed as a list | N/A | SCT_PREPARE_VERIFY_CMD
| **<a name="scylla_mgmt_upgrade_to_repo">scylla_mgmt_upgrade_to_repo</a>**  | Url to the repo of scylla manager version to upgrade to for management tests | N/A | SCT_SCYLLA_MGMT_UPGRADE_TO_REPO
| **<a name="stress_cmd_w">stress_cmd_w</a>**  | cassandra-stress commands.<br>You can specify everything but the -node parameter, which is going to<br>be provided by the test suite infrastructure.<br>multiple commands can passed as a list | N/A | SCT_STRESS_CMD_W
| **<a name="stress_cmd_r">stress_cmd_r</a>**  | cassandra-stress commands.<br>You can specify everything but the -node parameter, which is going to<br>be provided by the test suite infrastructure.<br>multiple commands can passed as a list | N/A | SCT_STRESS_CMD_R
| **<a name="stress_cmd_m">stress_cmd_m</a>**  | cassandra-stress commands.<br>You can specify everything but the -node parameter, which is going to<br>be provided by the test suite infrastructure.<br>multiple commands can passed as a list | N/A | SCT_STRESS_CMD_M
| **<a name="prepare_write_cmd">prepare_write_cmd</a>**  | cassandra-stress commands.<br>You can specify everything but the -node parameter, which is going to<br>be provided by the test suite infrastructure.<br>multiple commands can passed as a list | N/A | SCT_PREPARE_WRITE_CMD
| **<a name="stress_cmd_no_mv">stress_cmd_no_mv</a>**  | cassandra-stress commands.<br>You can specify everything but the -node parameter, which is going to<br>be provided by the test suite infrastructure.<br>multiple commands can passed as a list | N/A | SCT_STRESS_CMD_NO_MV
| **<a name="stress_cmd_no_mv_profile">stress_cmd_no_mv_profile</a>**  |  | N/A | SCT_STRESS_CMD_NO_MV_PROFILE
| **<a name="cs_user_profiles">cs_user_profiles</a>**  |  | N/A | SCT_CS_USER_PROFILES
| **<a name="cs_duration">cs_duration</a>**  |  | N/A | SCT_CS_DURATION
| **<a name="skip_download">skip_download</a>**  |  | N/A | SCT_SKIP_DOWNLOAD
| **<a name="sstable_file">sstable_file</a>**  |  | N/A | SCT_SSTABLE_FILE
| **<a name="sstable_url">sstable_url</a>**  |  | N/A | SCT_SSTABLE_URL
| **<a name="sstable_md5">sstable_md5</a>**  |  | N/A | SCT_SSTABLE_MD5
| **<a name="flush_times">flush_times</a>**  |  | N/A | SCT_FLUSH_TIMES
| **<a name="flush_period">flush_period</a>**  |  | N/A | SCT_FLUSH_PERIOD
| **<a name="new_scylla_repo">new_scylla_repo</a>**  |  | N/A | SCT_NEW_SCYLLA_REPO
| **<a name="new_version">new_version</a>**  |  | N/A | new_version
| **<a name="upgrade_node_packages">upgrade_node_packages</a>**  |  | N/A | SCT_UPGRADE_NODE_PACKAGES
| **<a name="test_sst3">test_sst3</a>**  |  | N/A | SCT_TEST_SST3
| **<a name="test_upgrade_from_installed_3_1_0">test_upgrade_from_installed_3_1_0</a>**  | Enable an option for installed 3.1.0 for work around a scylla issue if it's true | N/A | SCT_TEST_UPGRADE_FROM_INSTALLED_3_1_0
| **<a name="new_introduced_pkgs">new_introduced_pkgs</a>**  |  | N/A | SCT_NEW_INTRODUCED_PKGS
| **<a name="recover_system_tables">recover_system_tables</a>**  |  | N/A | SCT_RECOVER_SYSTEM_TABLES
| **<a name="stress_cmd_1">stress_cmd_1</a>**  | cassandra-stress commands.<br>You can specify everything but the -node parameter, which is going to<br>be provided by the test suite infrastructure.<br>multiple commands can passed as a list | N/A | SCT_STRESS_CMD_1
| **<a name="stress_cmd_sst3_prepare">stress_cmd_sst3_prepare</a>**  | cassandra-stress commands.<br>You can specify everything but the -node parameter, which is going to<br>be provided by the test suite infrastructure.<br>multiple commands can passed as a list | N/A | SCT_STRESS_CMD_SST3_PREPARE
| **<a name="prepare_write_stress">prepare_write_stress</a>**  | cassandra-stress commands.<br>You can specify everything but the -node parameter, which is going to<br>be provided by the test suite infrastructure.<br>multiple commands can passed as a list | N/A | SCT_PREPARE_WRITE_STRESS
| **<a name="stress_cmd_read_10m">stress_cmd_read_10m</a>**  | cassandra-stress commands.<br>You can specify everything but the -node parameter, which is going to<br>be provided by the test suite infrastructure.<br>multiple commands can passed as a list | N/A | SCT_STRESS_CMD_READ_10M
| **<a name="stress_cmd_read_clall">stress_cmd_read_clall</a>**  | cassandra-stress commands.<br>You can specify everything but the -node parameter, which is going to<br>be provided by the test suite infrastructure.<br>multiple commands can passed as a list | N/A | SCT_STRESS_CMD_READ_CLALL
| **<a name="stress_cmd_read_80m">stress_cmd_read_80m</a>**  | cassandra-stress commands.<br>You can specify everything but the -node parameter, which is going to<br>be provided by the test suite infrastructure.<br>multiple commands can passed as a list | N/A | SCT_STRESS_CMD_READ_20M
| **<a name="stress_cmd_sst3_verify_read">stress_cmd_sst3_verify_read</a>**  | cassandra-stress commands.<br>You can specify everything but the -node parameter, which is going to<br>be provided by the test suite infrastructure.<br>multiple commands can passed as a list | N/A | SCT_STRESS_CMD_SST3_VERIFY_READ
| **<a name="stress_cmd_sst3_verify_more">stress_cmd_sst3_verify_more</a>**  | cassandra-stress commands.<br>You can specify everything but the -node parameter, which is going to<br>be provided by the test suite infrastructure.<br>multiple commands can passed as a list | N/A | SCT_STRESS_CMD_SST3_VERIFY_MORE
